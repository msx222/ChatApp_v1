import streamlit as st
from dotenv import load_dotenv
import os

# Load .env from root
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ENV_PATH = os.path.join(BASE_DIR, ".env")
load_dotenv(ENV_PATH)

# ================================
# Import Workflows
# ================================
from src.workflows.technical.graph import technical_graph
from src.workflows.failure.graph import failure_graph
from src.workflows.law.graph import law_graph
from src.workflows.pdf.graph import pdf_graph
from src.workflows.general.graph import general_graph

# åˆ¤å®šAIãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆã‚ãªãŸã® LangGraph + RAG Dummyï¼‰
from src.workflows.judgement_ai.graph import build_judgement_graph

# Router
from src.router.router_chain import classify_query

# Chat UI Components
from ui.components.chat_display import render_chat
from ui.components.chat_input import render_input_box


# =========================================================
# Streamlit Settings
# =========================================================
st.set_page_config(
    page_title="ä¿å®‰åŸºæº–AI",
    page_icon="ğŸš—",
    layout="wide"
)

# =========================================================
# ChatGPTé¢¨ï¼ˆä¸­å¤®å¹…ï¼‰
# =========================================================
st.markdown("""
<style>
.block-container {
    max-width: 1100px !important;
    margin-left: auto !important;
    margin-right: auto !important;
}
</style>
""", unsafe_allow_html=True)


# =========================================================
# å›ºå®š Navbarï¼ˆå¾©æ´»ç‰ˆï¼‰
# =========================================================
NAVBAR_HEIGHT = 60

def navbar():
    st.markdown(f"""
    <div style="
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: {NAVBAR_HEIGHT}px;
        background-color: white;
        border-bottom: 1px solid #ddd;
        display: flex;
        align-items: center;
        padding: 0 25px;
        z-index: 9999999;
    ">
        <img src="https://www.mitsubishielectric-mobility.com/assets_gws_template_responsive/img/logo_ja.svg"
             style="height: 42px; margin-right: 12px;">
        <span style="font-size: 24px; font-weight: 600;">
            ğŸš— å“æƒ…äºŒ æ¥­å‹™ã‚µãƒãƒ¼ãƒˆAIï¼ˆPoCç‰ˆï¼‰
        </span>
    </div>
    """, unsafe_allow_html=True)

navbar()

# Main ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ Navbar åˆ†ä¸‹ã«ä¸‹ã’ã‚‹
st.markdown(f"""
<style>
.block-container {{
    padding-top: {NAVBAR_HEIGHT + 20}px !important;
}}
</style>
""", unsafe_allow_html=True)


# =========================================================
# Session State
# =========================================================
if "messages" not in st.session_state:
    st.session_state.messages = []

if "workflow_mode" not in st.session_state:
    st.session_state.workflow_mode = "è‡ªå‹•åˆ¤åˆ¥"

if "show_menu" not in st.session_state:
    st.session_state.show_menu = False


# =========================================================
# åˆ¤å®šçµæœ â†’ Markdown ã«å¤‰æ›ï¼ˆéå»äº‹ä¾‹ã¤ãï¼‰
# =========================================================
def generate_judgement_markdown(final_result):
    md = []
    overall = final_result["overall_judgement"]

    md.append(f"#### ğŸ“˜ æŠ€è¡“åŸºæº–ãƒ»é©åˆåˆ¤å®šï¼ˆç·åˆåˆ¤å®šï¼š{overall}ï¼‰\n")

    for art in final_result["articles"]:
        md.append("---\n")
        pdf = art.get("pdf_url")
        md.append(f"##### {art['article']}ï¼ˆ{art['title']}ï¼‰")
        if pdf:
            md.append(f"ğŸ”— [PDFãƒªãƒ³ã‚¯ã‚’è¦‹ã‚‹]({pdf})\n")

        for cl in art["clauses"]:
            md.append(f"###### â— {cl['clause']}ï¼š{cl['overall']}")
            for req in cl["requirements"]:
                md.append(f"""
- **R{req["req_id"]}**: {req["text"]}
    - åˆ¤å®š: {req["judgement"]}
    - ä¿¡é ¼åº¦: {req["confidence"]:.2f}
    - ç†ç”±: {req["reasoning"]}
""")

    # ---- éå»äº‹ä¾‹ï¼ˆä»Šã¯ãƒ€ãƒŸãƒ¼ï¼šå°†æ¥RAGï¼‰ ----
    md.append("---")
    md.append("#### ğŸ›  éå»ãƒ»é¡ä¼¼ä¸å…·åˆäº‹ä¾‹ï¼ˆå‚è€ƒï¼‰")

    past_cases = [
        {"year": 2022, "title": "å‰ç…§ç¯ é’è‰²ç‚¹ç¯ã®ä¸é©åˆ", "category": "ç¯ç«",
         "desc": "é’è‰²LEDãŒåŸå› ã§ä¸é©åˆã€‚"},
        {"year": 2021, "title": "åˆ¶å‹•ç¯ å…‰åº¦ä¸è¶³", "category": "ç¯ç«",
         "desc": "å…‰åº¦ãŒåŸºæº–å€¤ä¸è¶³ã§ä¸é©åˆã€‚"}
    ]

    for case in past_cases:
        md.append(f"""
##### â— {case["year"]}å¹´ã€Œ{case["title"]}ã€
- åŒºåˆ†ï¼š{case["category"]}
- å†…å®¹ï¼š{case["desc"]}
""")

    return "\n".join(md)



# =========================================================
# Chatè¡¨ç¤º
# =========================================================
render_chat(st.session_state.messages)


# =========================================================
# å…¥åŠ›æ¬„ï¼ˆï¼‹ãƒ¢ãƒ¼ãƒ‰é¸æŠï¼‰
# =========================================================
def chat_ui_row():
    col_plus, col_input = st.columns([0.08, 0.92])

    with col_plus:
        menu = st.button("ï¼‹", key="menu")

    with col_input:
        msg = st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            accept_file="multiple",
            # file_type=ALLOWED_FILE_TYPES
        )

    return msg, menu

user_msg, menu_clicked = chat_ui_row()


# ãƒ¢ãƒ¼ãƒ‰ãƒ¡ãƒ‹ãƒ¥ãƒ¼
if menu_clicked:
    st.session_state.show_menu = not st.session_state.show_menu

if st.session_state.show_menu:
    st.session_state.workflow_mode = st.radio(
        "AIãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
        [
            "è‡ªå‹•åˆ¤åˆ¥",
            "æŠ€è¡“åŸºæº–ãƒ»é©åˆåˆ¤å®š",
            "ä¸å…·åˆè§£æ",
            "æ³•åˆ¶åº¦èª¬æ˜",
            "PDFè§£æ",
            "é€šå¸¸QA",
        ]
    )


# =========================================================
# å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†
# =========================================================
if user_msg:

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒ–ãƒ«ã¨ã—ã¦ãƒãƒ£ãƒƒãƒˆã«è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": user_msg})

    # è‡ªå‹•åˆ¤åˆ¥
    mode = st.session_state.workflow_mode
    if mode == "è‡ªå‹•åˆ¤åˆ¥":
        detect = classify_query(user_msg)
        workflow = detect["workflow"]
    else:
        workflow = {
            "æŠ€è¡“åŸºæº–ãƒ»é©åˆåˆ¤å®š": "judgement",
            "ä¸å…·åˆè§£æ": "failure",
            "æ³•åˆ¶åº¦èª¬æ˜": "law",
            "PDFè§£æ": "pdf",
            "é€šå¸¸QA": "general",
        }.get(mode, "general")

    # åˆ¤å®šAIï¼ˆãƒ•ãƒ«å‡ºåŠ› â†’ ãƒãƒ£ãƒƒãƒˆã« Markdownï¼‰
    if workflow == "judgement":
        graph = build_judgement_graph()

        with st.spinner("é©åˆæ€§ã‚’åˆ¤å®šä¸­â€¦"):
            state = graph.invoke({"input_text": user_msg})

        final = state["final_result"]
        md = generate_judgement_markdown(final)

        st.session_state.messages.append(
            {"role": "assistant", "content": md}
        )

    else:
        # ãã®ä»–ã®é€šå¸¸QAç³»
        graphs = {
            "failure": failure_graph,
            "law": law_graph,
            "pdf": pdf_graph,
            "general": general_graph,
        }
        graph = graphs[workflow]

        with st.spinner("AIãŒå›ç­”ç”Ÿæˆä¸­â€¦"):
            result = graph.invoke({"user_query": user_msg})

        answer = result.get("answer", "å¿œç­”ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        st.session_state.messages.append(
            {"role": "assistant", "content": answer}
        )

    st.rerun()
